1 - get the providence corpus
    python scripts/download_providence_csvs.py --out_directory_name data/children_csvs
2 - Run tokenizations and creation of text training files:
    python scripts/create_training_files.py --csvs_directory data/children_csvs/ --out_directory_name data/tokenized/
3 - Run the models
    Train and save models using paraphone scripts. For example, for a orthographic word level language model of order 5, run this script to train the model and save the model on a folder `trained`
    python scripts/models/ngram_lm.py --train_file data/tokenized/providence_orthographic_tokenized_in_words.txt --out_directory trained --out_filename fivegram_lm_orthographic_words --ngram_size 5
4 - Run the tasks
    Test the trained models in the previous step on the syntactic tasks. For example, for the fivegram orthographic words language model, run :
    python scripts/run_tasks.py --train_file data/tokenized/providence_orthographic_tokenized_in_words.txt --tasks_folder data/tasks/ --no-phonemize --tokenize_in_words --ngram_model trained/fivegram_lm_orthographic_words.json --out_filename fivegram_lm_orthographic_words

    `--phonemize` argument means whether phonemize or not the sentences. Since, this language model works on orthographic form, phonemization is not needed.
    `--tokenize_in_words` argument means whether tokenize in words or not the sentences. This language model works with words, so we need the word tokenization.
